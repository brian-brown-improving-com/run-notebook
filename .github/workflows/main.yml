# This is a basic workflow to help you get started with Actions

name: First Workflow

# Controls when the workflow will run
on:

  ## Triggers the workflow on push or pull request events but only for the "main" branch
  ##push:
  #  branches: [ "main" ]
  ##pull_request:
  #  branches: [ "main" ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

env:
  DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}

permissions:
  id-token: write
  contents: read
  #pages: write

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  only-job:
  
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # timeout assumes that 5 minutes are needed for the cluster to spin up, 30 minutes are needed for the notebook to run, plus 5 minutes slack
    timeout-minutes: 40
    
    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - name: Check out the repo
        uses: actions/checkout@v4

      # This is the secret sauce for getting GitHub to work with Azure
      # Create an "Enterprise application" (App Registration) in Entra (Azure Databricks)
      # Create a "Federated Credential" for that App Registration ("bcb3654v1app")
      # (https://learn.microsoft.com/en-us/entra/workload-id/workload-identity-federation-create-trust?pivots=identity-wif-apps-methods-azp#github-actions)
      # (Certificates and Secrets)
      # (example: {Organization: brian-brown-improving-com, Repository: github-actions, Entity type: branch, Based on selection: main})

      # AADSTS700213: No matching federated identity record found for presented assertion subject 'repo:brian-brown-improving-com/upload-dbfs-temp:ref:refs/heads/main'. Please note that the matching is done using a case-sensitive comparison. Check your federated identity credential Subject, Audience and Issuer against the presented assertion. https://learn.microsoft.com/entra/workload-id/workload-identity-federation Trace ID: 0b7f071e-562b-413a-a969-3514ff0f0600 Correlation ID: 50ba4580-bd10-4e40-9a78-27c1845fb6c0 Timestamp: 2024-10-21 17:13:36Z

      # Obtain an AAD token and use it to upload to Databricks.
      # Note: If running on AWS or GCP, you can directly pass your service principal
      # token via the databricks-host input instead
      - name: Log into Azure
        uses: Azure/login@v2
        with:
          #auth-type: IDENTITY
          auth-type: SERVICE_PRINCIPAL
          # creds: ${{ secrets.AZURE_CREDENTIALS }}
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          #subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          allow-no-subscriptions: true
          #enable-AzPSSession: true

      # Get an AAD token for the service principal,
      # and store it in the DATABRICKS_TOKEN environment variable for use in subsequent steps.
      # We set the `resource` parameter to the programmatic ID for Azure Databricks.
      # See https://docs.microsoft.com/en-us/azure/databricks/dev-tools/api/latest/aad/service-prin-aad-token#--get-an-azure-ad-access-token for details.
      - name: Generate and save AAD token
        id: generate-token
        #run: |
        #  echo "DATABRICKS_TOKEN=$(az account get-access-token \
        #  --resource=2ff814a6-3304-4ab8-85cb-cd0e6f879c1d \
        #  --query accessToken -o tsv)" >> $GITHUB_ENV
        run: |
          echo "DATABRICKS_TOKEN=$(curl -X POST -H 'Content-Type: application/x-www-form-urlencoded' \
            https://login.microsoftonline.com/${{ secrets.AZURE_TENANT_ID }}/oauth2/v2.0/token \
            -d 'client_id=${{ secrets.AZURE_APPLICATION_ID }}' \
            -d 'grant_type=client_credentials' \
            -d 'scope=2ff814a6-3304-4ab8-85cb-cd0e6f879c1d%2F.default' \
            -d 'client_secret=${{ secrets.AZURE_SP_CLIENT_SECRET }}' |  jq -r  '.access_token')" >> $GITHUB_ENV

      # Runs a single command using the runners shell
      - name: Say hello, world (sanity check)
        run: echo Hello, world!

      #- name: Get directory (sanity check)
      #  run: ls
    
      - name: setup python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8 #install the python version needed

      - name: refresh repo in Databricks
      
        #env:
        #  DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        #  DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        #run: |
        #  python -m pip install --upgrade databricks-cli
        #  databricks repos update --path "/Repos/realadmin@brianchristopherbrownhotmai.onmicrosoft.com/run-notebook" --branch "main"
        ###### Error fetching repo ID for /Repos/realadmin@brianchristopherbrownhotmai.onmicrosoft.com/run-notebook: HTTP code: 401, Credential was not sent or was of an unsupported type for this API.

        #env:
        #  databricks-host: ${{ secrets.DATABRICKS_HOST }}
        #  databricks-token: ${{ secrets.DATABRICKS_STAGING_TOKEN }}
        #run: |
        #  python -m pip install --upgrade databricks-cli
        #  databricks repos update --path "/Repos/realadmin@brianchristopherbrownhotmai.onmicrosoft.com/run-notebook" --branch "main"
        ###### Error: b'{"error_code":"RESOURCE_DOES_NOT_EXIST","message":"Git folder (Repo) could not be found"}'
        
        env:
          databricks-host: ${{ secrets.DATABRICKS_HOST }}
          databricks-token: ${{ secrets.DATABRICKS_STAGING_TOKEN }}
        run: |
          python -m pip install --upgrade databricks-cli
          databricks repos update --repo-id ${{ secrets.REPO_ID }} --branch "main"

      #- name: Build wheel
      #  run:
      #    python setup.py bdist_wheel
      # python: can't open file '/home/runner/work/github-actions/github-actions/setup.py': [Errno 2] No such file or directory
      
      #- name: Upload wheel
      #  uses: databricks/upload-dbfs-temp@v0
      #  id: upload_wheel
      #  with:
      #    local-path: dist/my-project.whl

      #- name: Azure CLI script
      #  uses: azure/cli@v2
      #  with:
      #    azcliversion: latest
      #    inlineScript: |
      #      az account show

      #- name: Azure PowerShell script
      #  uses: azure/powershell@v2
      #  with:
      #    azPSVersion: "latest"
      #    inlineScript: |
      #      Get-AzContext

      - name: Trigger model training notebook from PR branch
        uses: databricks/run-notebook@v0
        with:
          databricks-host: ${{ secrets.DATABRICKS_HOST }}
          databricks-token: ${{ secrets.DATABRICKS_STAGING_TOKEN }}
          
          #local-notebook-path: MyMainNotebook.ipynb # basically, it's hello, world
          
          #local-notebook-path: hello-world.ipynb # currently includes attempt to query table in UC via SQL
          
          #local-notebook-path: find-and-run-notebook.ipynb # calls a notebook in github repo that calls a hello-workd notebook in Databricks repo

          #local-notebook-path: deploy-to-model-serving.ipynb

          #local-notebook-path: "/run-notebook/04 - Real-time Deployment/4.1 - Real-time Deployment with Model Serving - BCB.ipynb"
          # fails with "'local-notebook-path' input must be a relative path"
          
          #local-notebook-path: "/04 - Real-time Deployment/4.1 - Real-time Deployment with Model Serving - BCB"
          # fails with 'local-notebook-path' input must be a relative path"

          # using guidance from github.com/databricks/run-notebook/blob/main/action.yml ("ABSOLUTE path in the Databricks workspace"):
          local-notebook-path: "04 - Real-time Deployment/4.1 - Real-time Deployment with Model Serving - BCB.ipynb"

          # using guidance from github.com/databricks/run-notebook/blob/main/action.yml ("ABSOLUTE path in the Databricks workspace"):
          #workspace-notebook-path: "/Repos/run-notebook-repo/run-notebook/hello-world"
          # fails with "Only RELATIVE paths are currently supported for remote repositories. Paths must not begin with '/'."
          
          # again, using guidance from github.com/databricks/run-notebook/blob/main/action.yml ("ABSOLUTE path in the Databricks workspace"):
          #workspace-notebook-path: "/Users/realadmin@brianchristopherbrownhotmai.onmicrosoft.com/hello-world"
          # agaijn, fails with "Only RELATIVE paths are currently supported for remote repositories. Paths must not begin with '/'."

          #workspace-notebook-path: "Repos/run-notebook-repo/run-notebook/hello-world"
          # fails with "'workspace-notebook-path' input must be an ABSOLUTE path"

          #workspace-notebook-path: "../realadmin@brianchristopherbrownhotmai.onmicrosoft.com/hello-world"
          # fails with "'workspace-notebook-path' input must be an ABSOLUTE path"

          #workspace-notebook-path: "Users/realadmin@brianchristopherbrownhotmai.onmicrosoft.com/hello-world"
          # fails with "'workspace-notebook-path' input must be an ABSOLUTE path"
          
          #workspace-notebook-path: "Users/realadmin@brianchristopherbrownhotmai.onmicrosoft.com/hello-world.ipynb"
          # fails with "'workspace-notebook-path' input must be an ABSOLUTE path"

          #workspace-notebook-path: "/Repos/deploy-from-github-to-model-serving/deploy-from-github-to-model-serving/deploy-from-github-to-model-serving/deploy-from-github-to-model-serving"

          # If the current workflow is triggered from a PR,
          # run notebook code from the PR's head commit, otherwise use github.sha.
          git-commit: ${{ github.event.pull_request.head.sha || github.sha }}
          # The cluster JSON below is for Azure Databricks. On AWS and GCP, set
          # node_type_id to an appropriate node type, e.g. "i3.xlarge" for
          # AWS or "n1-highmem-4" for GCP
          new-cluster-json: >
            {
              "num_workers": 1,
              "spark_version": "13.3.x-cpu-ml-scala2.12",
              "node_type_id": "Standard_D3_v2",
              "data_security_mode": "SINGLE_USER"
            }
          # Grant all users view permission on the notebook results
          #access-control-list-json: >
          #  [
          #    {
          #      "group_name": "users",
          #      "permission_level": "CAN_VIEW"
          #    }
          #  ]

      ## Runs a set of commands using the runners shell
      #- name: Run a multi-line script
      #  run: |
      #    echo Add other actions to build,
      #    echo test, and deploy your project.

      - name: Say goodbye, world (sanity check)
        run: echo Goodbye, world!
